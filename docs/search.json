[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Online supplementary materials",
    "section": "",
    "text": "This document contains the online supplementary materials of Mulder, Luijken, Penning-de Vries, and Hamaker (under review). R code and Mplus syntax for the analysis of the empirical example, and for the simulation study can be found below. All analyses in R were done using version 4.2.2 R Core Team (2022b). We relied on functions from the R packages\n\nWeightIt (version 0.14.0) by Greifer (2023b);\ncobalt (version 4.5.0) by Greifer (2023a);\nboot (version 1.3-28) by Canty and Ripley (2022);\nmice (version 3.16.0) by Buuren and Groothuis-Oudshoorn (2011);\nforeign (version 0.8-83) by R Core Team (2022a);\ndplyr (version 1.1.4) by Wickham et al. (2023);\npurrr (version 1.0.2) by Wickham and Henry (2023); and\nggplot2 (version 3.4.4) by Wickham (2016).\n\nAnalyses in Mplus were done using version 8.9 Muthén and Muthén (2017)."
  },
  {
    "objectID": "index.html#data-cleaning-and-preparation",
    "href": "index.html#data-cleaning-and-preparation",
    "title": "Online supplementary materials",
    "section": "Data cleaning and preparation",
    "text": "Data cleaning and preparation\nExploration of the data with describe(df_target) from the psych package revealed individuals with implausible values: These were removed from the dataset. Missing values in this sample were then filled in by single imputation, and the data were exported to Mplus.\n\n# Descriptive sample\npsych::describe(df_target)\n\n# Prepare sample data for analyses\ndf_target_clean &lt;- df_target |&gt;\n  filter(is.na(weight_0) | (weight_0 &gt; 20 & weight_0 &lt; 155)) |&gt;\n  filter(is.na(weight_1) | (weight_1 &gt; 30 & weight_1 &lt; 160)) |&gt;\n  filter(is.na(weight_3) | (weight_3 &gt; 30 & weight_3 &lt; 160)) |&gt;\n  filter(is.na(hourHPA_3) | hourHPA_3 &lt; 168) |&gt;\n  rowwise(ID) |&gt;\n  mutate(\n    age = mean(c(age_0, age_1, age_2, age_3), na.rm = TRUE),\n    sex = mean(c(sex_0, sex_1, sex_2, sex_3), na.rm = TRUE) - 1,\n    comor1_0 = if_else(sum(c_across(starts_with(\"d\") & ends_with(\"_0\"))) == 1, 1, 0),\n    comor2_0 = if_else(sum(c_across(starts_with(\"d\") & ends_with(\"_0\"))) &gt; 1, 1, 0),\n    comor1_1 = if_else(sum(c_across(starts_with(\"d\") & ends_with(\"_1\"))) == 1, 1, 0),\n    comor2_1 = if_else(sum(c_across(starts_with(\"d\") & ends_with(\"_1\"))) &gt; 1, 1, 0),\n    comor1_2 = if_else(sum(c_across(starts_with(\"d\") & ends_with(\"_2\"))) == 1, 1, 0),\n    comor2_2 = if_else(sum(c_across(starts_with(\"d\") & ends_with(\"_2\"))) &gt; 1, 1, 0),\n    smoke_0 = smoke_0 - 1,\n    smoke_1 = smoke_1 - 1,\n    smoke_2 = smoke_2 - 1,\n    smoke_3 = smoke_3 - 1\n  ) |&gt;\n  ungroup() |&gt;\n  select(\n    -contains(\"Cret\"), \n    -contains(\"Pipe\"), \n    -contains(\"Cigar\"), \n    -starts_with(\"d\"),\n    -sex_0, -sex_1, -sex_2, -sex_3,\n    -age_0, -age_1, -age_2, -age_3,\n    -smoke_0, -smoke_3,\n    -hourHPA_3, -geznd_3, -sHeart_3, -alc_3\n  ) |&gt;\n  filter(sex == 0 | sex == 1) |&gt;\n  mutate_at(c(\"smoke_1\", \"smoke_2\", \"sHeart_0\", \"sHeart_1\", \"sHeart_2\", \"sex\", \n              \"comor1_0\", \"comor2_0\", \"comor1_1\", \"comor2_1\", \"comor1_2\",\n              \"comor2_2\"), as.factor) |&gt;\n  mutate_at(c(\"geznd_0\", \"geznd_1\", \"geznd_2\", \"alc_0\", \"alc_1\", \"alc_2\"), as.ordered)\n\n# Single imputation\nfit_imp &lt;- mice(df_target_clean, m = 1, seed = 20230728)\ndf_target_imp &lt;- complete(fit_imp)\nsummary(df_target_imp)\n\n# Export for Mplus\nfactor_to_numeric &lt;- function(f){ as.numeric(levels(f))[f] }\n\ndf_target_imp |&gt;\n  mutate_if(is.factor, factor_to_numeric) |&gt;\n  mutate(smXco1_2 = smoke_1 * comor1_2) |&gt;\n  utils::write.table(\n    file = \"./Mplus/df_target_imp.dat\",\n    sep = \"\\t\", \n    col.names = FALSE, \n    row.names = FALSE, \n    na = \"-999\",\n    quote = FALSE\n  )"
  },
  {
    "objectID": "index.html#weighting",
    "href": "index.html#weighting",
    "title": "Online supplementary materials",
    "section": "Weighting",
    "text": "Weighting\nStabilized inverse-probability-of-exposure weights were computed, and covariate imbalance was assessed before and after weighted. Below you can also find R code for the creation of Figure 3 in the main manuscript.\n\n# Compute inverse-probability-of-exposure weights\nSW_smoke &lt;- weightitMSM(\n  list(\n    smoke_1 ~ age + sex + # Baseline\n      geznd_0 + weight_0 + alc_0 + hourHPA_0 + sHeart_0 + comor1_0 + comor2_0 + # Lag 1\n      geznd_1 + weight_1 + alc_1 + hourHPA_1 + sHeart_1 + comor1_1 + comor2_1, # Lag 0\n    smoke_2 ~ age + sex + # Baseline\n      geznd_0 + weight_0 + alc_0 + hourHPA_0 + sHeart_0 + comor1_0 + comor2_0 + # Lag 2\n      geznd_1 + weight_1 + alc_1 + hourHPA_1 + sHeart_1 + comor1_1 + comor2_1 + # Lag 1\n      geznd_2 + weight_2 + alc_2 + hourHPA_2 + sHeart_2 + comor1_2 + comor2_2 # Lag 0\n  ),\n  data = df_target_imp,\n  method = \"glm\", \n  stabilize = TRUE, \n  link = \"logit\"\n)\n\nsummary(SW_smoke)\ndf_target_imp$SW_smoke &lt;- SW_smoke$weights\ndf_target_imp$PS_1 &lt;- SW_smoke$ps.list[[1]]\ndf_target_imp$PS_2 &lt;- SW_smoke$ps.list[[2]]\n\n# Examine positivity by overlap PS distributions\nplot_PS &lt;- df_target_imp |&gt;\n  select(ID, starts_with(\"smoke\"), starts_with(\"PS\")) |&gt;\n  mutate_at(c(\"smoke_1\", \"smoke_2\"), as.numeric) |&gt;\n  pivot_longer(\n    cols = -ID,\n    names_to = c(\"var\", \"time\"),\n    names_sep = \"_\", \n    names_transform = list(time = as.numeric)\n  ) |&gt;\n  pivot_wider(values_from = value, names_from = var) |&gt;\n  mutate(facet_time = factor(time, labels = c(\"Time 1\", \"Time 2\"))) |&gt;\n  ggplot(aes(x = PS, fill = as.factor(smoke))) +\n  geom_density(alpha = .7) +\n  facet_wrap( ~ facet_time) + \n  theme(\n    panel.background = element_rect(fill = \"white\"),\n    axis.text.x = element_text(color = \"black\"),\n    axis.title.y = element_blank(),\n    panel.border = element_rect(fill = NA, color = \"black\"),\n    plot.background = element_blank(),\n    legend.background = element_blank(),\n    legend.key = element_blank(),\n    legend.position = \"bottom\",\n    text = element_text(size = 20)\n  ) +\n  scale_fill_discrete(name = \"Exposure\", labels = c(\"Smoking\", \"Quit smoking\"))\n\nggsave(plot_PS, filename = \"./figures/plot_PS.pdf\")\n\n# Examine imbalance after reweighing\ntab_bal &lt;- bal.tab(\n  x = list(\n    smoke_1 ~ age + sex + # Baseline\n      geznd_0 + weight_0 + alc_0 + hourHPA_0 + sHeart_0 + comor1_0 + comor2_0 + # Lag 1\n      geznd_1 + weight_1 + alc_1 + hourHPA_1 + sHeart_1 + comor1_1 + comor2_1, # Lag 0\n    smoke_2 ~ age + sex + # Baseline\n      geznd_0 + weight_0 + alc_0 + hourHPA_0 + sHeart_0 + comor1_0 + comor2_0 + # Lag 2\n      geznd_1 + weight_1 + alc_1 + hourHPA_1 + sHeart_1 + comor1_1 + comor2_1 + # Lag 1\n      geznd_2 + weight_2 + alc_2 + hourHPA_2 + sHeart_2 + comor1_2 + comor2_2 # Lag 0\n  ),\n  data = df_target_imp,\n  stats = c(\"m\", \"ks\"),\n  weights = df_target_imp$SW_smoke,\n  which.time = .all, \n  un = TRUE\n)\n\nplot_love_names &lt;- c(\n  age = \"Age (years)\", \n  sex = \"Sex: male\",\n  geznd_0_1 = \"Health change t0: considerably poorer \",\n  geznd_0_2 = \"Health change t0: somewhat poorer\",\n  geznd_0_3 = \"Health change t0: same \",\n  geznd_0_4 = \"Health change t0: somewhat better \",\n  geznd_0_5 = \"Health change t0: considerably better\",\n  weight_0 = \"Weight t0 (kg)\",\n  alc_0_1 = \"Alcohol frequency t0: daily\",\n  alc_0_2 = \"Alcohol frequency t0: 5/6 PW\",\n  alc_0_3 = \"Alcohol frequency t0: 3/4 PW\",\n  alc_0_4 = \"Alcohol frequency t0: 1/2 PW\",\n  alc_0_5 = \"Alcohol frequency t0: 1/2 PM\",\n  alc_0_6 = \"Alcohol frequency t0: 1 P2M\",\n  alc_0_7 = \"Alcohol frequency t0: 1/2 PY\",\n  alc_0_8 = \"Alcohol frequency t0: never\",\n  hourHPA_0 = \"Physical activity t0 (hours per week)\",\n  sHeart_0 = \"Heart problems t0: yes\",\n  comor1_0 = \"Comorbidity t0: 1 diagnosis\",\n  comor2_0 = \"Comorbidity t0: &gt; 1 diagnoses\",\n  geznd_1_1 = \"Health change t1: considerably poorer\",\n  geznd_1_2 = \"Health change t1: somewhat poorer\",\n  geznd_1_3 = \"Health change t1: same \",\n  geznd_1_4 = \"Health change t1: somewhat better \",\n  geznd_1_5 = \"Health change t1: considerably better\",\n  weight_1 = \"Weight t1 (kg)\",\n  alc_1_1 = \"Alcohol frequency t1: daily\",\n  alc_1_2 = \"Alcohol frequency t1: 5/6 PW\",\n  alc_1_3 = \"Alcohol frequency t1: 3/4 PW\",\n  alc_1_4 = \"Alcohol frequency t1: 1/2 PW\",\n  alc_1_5 = \"Alcohol frequency t1: 1/2 PM\",\n  alc_1_6 = \"Alcohol frequency t1: 1 P2M\",\n  alc_1_7 = \"Alcohol frequency t1: 1/2 PY\",\n  alc_1_8 = \"Alcohol frequency t1: never\",\n  hourHPA_1 = \"Physical activity t1 (hours per week)\",\n  sHeart_1 = \"Heart problems t1: yes\",\n  comor1_1 = \"Comorbidity t1: 1 diagnosis\",\n  comor2_1 = \"Comorbidity t1: &gt; 1 diagnoses\"\n)\n\nplot_love &lt;- love.plot(\n  x = tab_bal, \n  drop.distance = TRUE,\n  abs = TRUE,\n  thresholds = c(m = .2),\n  var.names = plot_love_names,\n  shapes = c(\"triangle filled\", \"circle filled\"),\n  sample.names = c(\"Unweighted\", \"PS weighted\"),\n  line = TRUE,\n  which.time = .all,\n  colors = TRUE, \n  stars = \"raw\",\n  position = \"bottom\"\n) +\n  labs(title = NULL) \n\nggsave(plot_love, filename = \"./figures/plot_love.pdf\", height = 8, width = 7)"
  },
  {
    "objectID": "index.html#estimating-effects",
    "href": "index.html#estimating-effects",
    "title": "Online supplementary materials",
    "section": "Estimating effects",
    "text": "Estimating effects\nThe below R code estimates the joint effect of smoking cessation on end-of-study body weight, and computed 95% bootstrapped confidence intervals.\n\n# Fit MSM\n## Using bootstrap for 95% CI\nfn_boot &lt;- function(data, i) {\n  df_boot &lt;- data[i,]\n  \n  # PS weighting for exposure\n  SW_smoke &lt;- weightitMSM(\n    list(\n      smoke_1 ~ age + sex + # Baseline\n      geznd_0 + weight_0 + alc_0 + hourHPA_0 + sHeart_0 + comor1_0 + comor2_0 + # Lag 1\n      geznd_1 + weight_1 + alc_1 + hourHPA_1 + sHeart_1 + comor1_1 + comor2_1, # Lag 0\n    smoke_2 ~ age + sex + # Baseline\n      geznd_0 + weight_0 + alc_0 + hourHPA_0 + sHeart_0 + comor1_0 + comor2_0 + # Lag 2\n      geznd_1 + weight_1 + alc_1 + hourHPA_1 + sHeart_1 + comor1_1 + comor2_1 + # Lag 1\n      geznd_2 + weight_2 + alc_2 + hourHPA_2 + sHeart_2 + comor1_2 + comor2_2 # Lag 0\n    ),\n    data = df_boot,\n    method = \"glm\", \n    stabilize = TRUE, \n    link = \"logit\"\n  )\n  \n  # Bring weights into the dataset\n  df_boot$weights &lt;- SW_smoke$weights\n  \n  # Fit outcome model\n  fit &lt;- glm(\n    formula = weight_3 ~ smoke_1 + smoke_2,\n    data = df_boot, \n    weights = weights\n  )\n  \n  return(\n    c(\n      coef(fit)[\"smoke_11\"],\n      coef(fit)[\"smoke_21\"],\n      coef(fit)[\"smoke_11\"] + coef(fit)[\"smoke_21\"]\n    )\n  )\n}\n\n### Perform bootstrap\nset.seed(20230725)\nout_boot &lt;- boot(df_target_imp, fn_boot, R = 999)\nboot.ci(out_boot, type = \"perc\", index = 1)"
  },
  {
    "objectID": "index.html#helper-functions",
    "href": "index.html#helper-functions",
    "title": "Online supplementary materials",
    "section": "Helper functions",
    "text": "Helper functions\nThree helper functions were defined which all work together to generate data and compute inverse-probability-of-exposure weights for a specific simulation condition.\n\nsimulate_datacompute_weightsrun_condition\n\n\nThis function generates data according to the data generating mechanism in Figure 4 of the main paper. Structural relations between variables are specified as polynomials of order 2. By default the parameters of the quadratic term (denoted by B2_...) are set to 0 such that only linear relationships between variables are specified (i.e., DGM 1). Using the argument param_funcForm, the parameters of quadratic terms can be set to other values, thereby allowing for data generated under DGMs 2 to 5. The params_prop_exposed argument sets the intercepts of the exposure-variables, thereby controlling the proportion exposed for each sample.\n\nsimulate_data &lt;- function(\n    sample_size, params_funcForm, params_prop_exposed, \n    # Wave 1\n    B0_L1 = 1, B_C0L1 = 0.1, B2_C0L1 = 0,\n    B0_A1 = 0, B_C0A1 = 0.1, B_L1A1 = 0.5, B2_L1A1 = 0, \n    # Wave 2\n    B0_L2 = 1, B_L1L2 = 0.3, B_A1L2 = 0.4, B_C0L2 = 0.1, \n      B2_C0L2 = 0, B2_L1L2 = 0,\n    B0_A2 = -.545, B_A1A2 = 0.8, B_L1A2 = 0.25, B_L2A2 = 0.5, B_C0A2 = 0.1,\n      B2_L1A2 = 0, B2_L2A2 = 0,\n    # Outcome\n    B0_Y = 0, B_L2Y = 0.3, B_L1Y = 0.15, B_A2Y = 0.4, B_A1Y = 0.2, B_C0Y = 0.1,\n      B2_L1Y = 0, B2_L2Y = 0, B2_C0Y = 0\n) { \n\n  # Set (mis)specified population values\n  eval(parse(text = params_funcForm))  \n  \n  # Set intercepts exposure model for proportion exposed\n  eval(parse(text = params_prop_exposed))\n\n  # Simulate data\n  C0 &lt;- rnorm(sample_size, mean = 4)\n \n  L1 &lt;- B0_L1 + # Intercept\n    B_C0L1 * C0 + # Linear\n    B2_C0L1 * I((C0 - mean(C0))^2) + # Quadratic \n    rnorm(sample_size)\n  \n  Pr_A1 &lt;- plogis(\n    B0_A1 + # Intercept\n    B_C0A1 * C0 + B_L1A1 * L1 + # Linear \n    B2_L1A1 * I((L1 - mean(L1))^2) # Quadratic \n  )\n  \n  A1 &lt;- rbinom(n = sample_size, size = 1, prob = Pr_A1) \n  \n  L2 &lt;- B0_L2 + # Intercept\n    B_L1L2 * L1 + B_A1L2 * A1 + B_C0L2 * C0 + # Linear \n    B2_C0L2 * I((C0 - mean(C0))^2) + B2_L1L2 * I((L1 - mean(L1))^2) + # Quadratic\n    rnorm(sample_size)\n  \n  Pr_A2 &lt;- plogis(\n    B0_A2 + # Intercept\n    B_L1A2 * L1 + B_A1A2 * A1 + B_L2A2 * L2 + B_C0A2 * C0 + # Linear \n    B2_L1A2 * I((L1 - mean(L1))^2) + B2_L2A2 * I((L2 - mean(L2))^2) # Quadratic\n  )\n  \n  A2 &lt;- rbinom(n = sample_size, size = 1, prob = Pr_A2)\n\n  Y &lt;- B0_Y + # Intercept\n    B_L2Y * L2 + B_L1Y * L1 + B_A2Y * A2 + B_A1Y * A1 + B_C0Y * C0 + # Linear \n    B2_L1Y * I((L1 - mean(L1))^2) + B2_L2Y * I((L2 - mean(L2))^2) + # Quadratic \n      B2_C0Y * I((C0 - mean(C0))^2) + \n    rnorm(sample_size)\n  \n  df &lt;- data.frame(\n    C0 = C0, \n    L1 = as.numeric(L1), \n    A1 = as.numeric(A1), \n    L2 = as.numeric(L2), \n    A2 = as.numeric(A2), \n    Y = as.numeric(Y), \n    Pr_A1 = Pr_A1, \n    Pr_A2 = Pr_A2\n  )\n\n  return(df)\n}\n\n\n\nThis function computes stabilized inverse-probability-of-exposure weights using using both a linear propensity score model, and a quadratic propensity score model. For DGMs 4 and 5, the quadratic propensity score model is correct.\n\n# Compute inverse probability of exposure weights\ncompute_weights &lt;- function(df, stabilized, m_A1_correct, m_A2_correct) {\n  \n  # Compute probability of treatment conditional on covariates\n  fit_ps1 &lt;- glm(A1 ~ C0 + L1, data = df, family = \"binomial\")\n  fit_ps2 &lt;- glm(A2 ~ C0 + L1 + A1 + L2, data = df, family = \"binomial\")\n  \n  fit_ps1_correct &lt;- glm(as.formula(m_A1_correct), data = df, family = \"binomial\")\n  fit_ps2_correct &lt;- glm(as.formula(m_A2_correct), data = df, family = \"binomial\")\n  \n  ps1_den &lt;- predict(fit_ps1, type = \"response\")\n  ps2_den &lt;- predict(fit_ps2, type = \"response\")\n  \n  ps1_den_correct &lt;- predict(fit_ps1_correct, type = \"response\")\n  ps2_den_correct &lt;- predict(fit_ps2_correct, type = \"response\")\n    \n  # Compute probability of treatment conditional on treatment history\n  fit_ps1_num &lt;- glm(A1 ~ 1, data = df, family = \"binomial\")\n  fit_ps2_num &lt;- glm(A2 ~ A1, data = df, family = \"binomial\")\n    \n  ps1_num &lt;- predict(fit_ps1_num, type = \"response\") \n  ps2_num &lt;- predict(fit_ps2_num, type = \"response\") \n    \n  # Compute stabilized inverse probability weights \n  ipw1 &lt;- df$A1 * (ps1_num / ps1_den) + (1 - df$A1) * ((1 - ps1_num) / (1 - ps1_den))\n  ipw2 &lt;- df$A2 * (ps2_num / ps2_den) + (1 - df$A2) * ((1 - ps2_num) / (1 - ps2_den))\n    \n  ipw1_correct &lt;- df$A1 * (ps1_num / ps1_den_correct) + (1 - df$A1) * ((1 - ps1_num) / (1 - ps1_den_correct))\n  ipw2_correct &lt;- df$A2 * (ps2_num / ps2_den_correct) + (1 - df$A2) * ((1 - ps2_num) / (1 - ps2_den_correct))\n  \n  # Compute stabilized weights\n  W &lt;- ipw1 * ipw2\n  W_correct &lt;- ipw1_correct * ipw2_correct\n  df &lt;- df |&gt;\n    dplyr::bind_cols(ps1 = ps1_den, ps2 = ps2_den, W = W, W_correct = W_correct)\n  \n  return(df)\n}\n\n\n\nThis function controls the simulation process for a particular simulation scenario. Based on the population parameter values associated with a particular simulation scenario, it repeatedly generates data using simulate_data, and estimates the always-exposed versus never-exposed effect for an IPW method, a lavaan-based SEM method (not in main manuscript), a t-test (not in main manuscript), and a naive regression method. It outputs three dataframes:\n\ndf_performance, containing performance metrics such as bias, convergence issues, etc. per estimation method;\ndf_estimates, containing the parameter estimates across all replications; and\ndf_prop_exposed, containing the proportion exposed in the sample per generated sample.\n\nEach generated dataset is also saved, and exported for analysis in Mplus.\n\n# Function to run simulations for single condition\nrun_condition &lt;- function(condition, n_reps, p, save_folder) {\n  \n  # Extract information\n  sample_size &lt;- as.numeric(condition[\"sample_size\"])\n  id_condition &lt;- as.numeric(condition[\"id_condition\"])\n  id_funcForm &lt;- as.numeric(condition[\"id_funcForm\"])\n  PV_A1 &lt;- as.numeric(condition[\"PV_A1\"])\n  PV_AvN &lt;- as.numeric(condition[\"PV_AvN\"])\n  \n  # Memory allocation\n  df_IPW_A1 &lt;- df_regression_A1 &lt;- df_correct_A1 &lt;- df_path_A1 &lt;- \n    df_IPW_AvN &lt;- df_regression_AvN &lt;- df_ttest_AvN &lt;- df_path_AvN &lt;- \n    df_correct_AvN &lt;- \n    data.frame(\n      matrix(\n        data = NA, \n        ncol = 2, \n        nrow = n_reps, \n        dimnames = list(NULL, c(\"PV\",\"est\"))\n      )\n    ) |&gt;\n  bind_cols(inadmissible = FALSE, not_converged = FALSE, error = FALSE)\n  \n  df_prop_exposed &lt;- data.frame(\n    matrix(\n      data = NA,\n      ncol = 2,\n      nrow = n_reps,\n      dimnames = list(NULL, c(\"n_exposed_A1\", \"n_exposed_A2\"))\n    )\n  )\n  \n  # Create folder for data save\n  save_path &lt;- file.path(getwd(), save_folder, paste0(\"condition\", id_condition))\n  dir.create(save_path)\n  \n  # Replications\n  for (i in 1:n_reps) {\n    \n    # Fill in population values\n    df_IPW_A1[i, \"PV\"] &lt;- df_regression_A1[i, \"PV\"] &lt;- df_path_A1[i, \"PV\"] &lt;- \n      df_correct_A1[i, \"PV\"] &lt;- PV_A1\n    \n    df_IPW_AvN[i, \"PV\"] &lt;- df_regression_AvN[i, \"PV\"] &lt;- \n      df_ttest_AvN[i, \"PV\"] &lt;- df_path_AvN[i, \"PV\"] &lt;- \n      df_correct_AvN[i, \"PV\"] &lt;- PV_AvN\n    \n    # Simulate data\n    df_dat &lt;- simulate_data(sample_size, \n      params_funcForm = condition[[\"funcForm\"]],\n      params_prop_exposed = condition[[\"prop_exposed_funcForm\"]]\n    ) |&gt;\n      compute_weights(\n        stabilized = TRUE,\n        m_A1_correct = condition[[\"m_A1_correct\"]],\n        m_A2_correct = condition[[\"m_A2_correct\"]]\n      )\n    \n    # Save data\n    utils::write.table(df_dat, \n      file = file.path(save_path, paste0(\"df\", i, \"_condition\", id_condition, \".dat\")),\n      sep = \"\\t\", col.names = FALSE, row.names = FALSE, na = \"-999\"\n    )\n    \n    # Fill in proportion exposed in sample\n    df_prop_exposed[i, \"n_exposed_A1\"] &lt;- sum(df_dat$A1)\n    df_prop_exposed[i, \"n_exposed_A2\"] &lt;- sum(df_dat$A2)\n    \n    # Fit models\n    fit_IPW &lt;- tryCatch(\n      {\n        glm(Y ~ A1 + A2, data = df_dat, weights = W)\n      },\n      error = function(e) {\n        df_IPW_A1[i, \"error\"] &lt;&lt;- TRUE\n        df_IPW_AvN[i, \"error\"] &lt;&lt;- TRUE\n      }\n    )\n      \n    fit_regression &lt;- tryCatch(\n      {\n        lm(Y ~ A1 + A2, data = df_dat)\n      },\n      error = function(e) {\n        df_regression_A1[i, \"error\"] &lt;&lt;- TRUE\n        df_regression_AvN[i, \"error\"] &lt;&lt;- TRUE\n      }\n    )\n    \n    fit_path &lt;- tryCatch(\n      {\n        suppressWarnings(\n          lavaan(model = m_path, data = df_dat, ordered = c(\"A1\", \"A2\"))\n        )\n      },\n      error = function(e) {\n        df_path_A1[i, \"error\"] &lt;&lt;- TRUE\n        df_path_AvN[i, \"error\"] &lt;&lt;- TRUE\n      }\n    )\n    \n    fit_correct &lt;- tryCatch(\n      {\n        glm(Y ~ A1 + A2, data = df_dat, weights = W_correct)\n      },\n      error = function(e) {\n        df_correct[i, \"error\"] &lt;&lt;- TRUE\n      }\n    )\n    \n    fit_ttest &lt;- tryCatch(\n      { \n        df_AvN &lt;- filter(df_dat, A1 == 1 & A2 == 1 | A1 == 0 & A2 == 0) \n        t.test(Y ~ A1, data = df_AvN)\n      },\n      error = function(e) {\n        df_ttest_AvN[i, \"error\"] &lt;&lt;- TRUE\n      }\n    )\n    \n    # Check convergence and inadmissibility of IPTW-SEM results\n    if (is.null(fit_path) || !lavaan::lavInspect(fit_path, what = \"converged\")) {\n      df_path_A1[i, \"not_converged\"] &lt;- TRUE\n      df_path_AvN[i, \"not_converged\"] &lt;- TRUE\n    }\n    \n    if (!suppressWarnings(lavaan::lavInspect(fit_path, what = \"post.check\"))) {\n      df_path_A1[i, \"inadmissible\"] &lt;- TRUE\n      df_path_AvN[i, \"inadmissible\"] &lt;- TRUE\n    }\n    \n    # Extract point estimates\n    tryCatch(\n      {\n        df_IPW_A1[i, \"est\"] &lt;- coef(fit_IPW)[\"A1\"]\n        \n        df_Y_0 &lt;- data.frame(C0 = df_dat$C0, A1 = 0, A2 = 0)\n        df_Y_0$Y_0 &lt;- predict(fit_IPW, newdata = df_Y_0)\n        \n        df_Y_1 &lt;- data.frame(C0 = df_dat$C0, A1 = 1, A2 = 1)\n        df_Y_1$Y_1 &lt;- predict(fit_IPW, newdata = df_Y_1)\n        \n        df_IPW_AvN[i, \"est\"] &lt;- mean(df_Y_1$Y_1 - df_Y_0$Y_0)\n      },\n      error = function(e) {\n        df_IPW_A1[i, \"error\"] &lt;&lt;- TRUE\n        df_IPW_AvN[i, \"error\"] &lt;&lt;- TRUE\n      }\n    )\n    \n    tryCatch(\n      {\n        df_regression_A1[i, \"est\"] &lt;- coef(fit_regression)[\"A1\"]\n        \n        df_Y_0 &lt;- data.frame(C0 = df_dat$C0, A1 = 0, A2 = 0)\n        df_Y_0$Y_0 &lt;- predict(fit_regression, newdata = df_Y_0)\n        \n        df_Y_1 &lt;- data.frame(C0 = df_dat$C0, A1 = 1, A2 = 1)\n        df_Y_1$Y_1 &lt;- predict(fit_regression, newdata = df_Y_1)\n        \n        df_regression_AvN[i, \"est\"] &lt;- mean(df_Y_1$Y_1 - df_Y_0$Y_0)\n      },\n      error = function(e) {\n        df_regression_A1[i, \"error\"] &lt;&lt;- TRUE\n        df_regression_AvN[i, \"error\"] &lt;&lt;- TRUE\n      }\n    )\n    \n    tryCatch(\n      {\n        df_path_A1[i, \"est\"] &lt;- parameterEstimates(fit_path)[32, \"est\"]\n        df_path_AvN[i, \"est\"] &lt;- parameterEstimates(fit_path)[33, \"est\"]\n      },\n      error = function(e) {\n        df_regression_A1[i, \"error\"] &lt;&lt;- TRUE\n        df_regression_AvN[i, \"error\"] &lt;&lt;- TRUE\n      }\n    )\n    \n    tryCatch(\n      {\n        df_ttest_AvN[i, \"est\"] &lt;- fit_ttest$estimate[2] - fit_ttest$estimate[1]\n      },\n      error = function(e) {\n        df_ttest_AvN[i, \"error\"] &lt;&lt;- TRUE\n      }\n    )\n    \n    tryCatch(\n      {\n        df_correct_A1[i, \"est\"] &lt;- coef(fit_correct)[\"A1\"]\n        \n        df_Y_0 &lt;- data.frame(C0 = df_dat$C0, A1 = 0, A2 = 0)\n        df_Y_0$Y_0 &lt;- predict(fit_correct, newdata = df_Y_0)\n        \n        df_Y_1 &lt;- data.frame(C0 = df_dat$C0, A1 = 1, A2 = 1)\n        df_Y_1$Y_1 &lt;- predict(fit_correct, newdata = df_Y_1)\n        \n        df_correct_AvN[i, \"est\"] &lt;- mean(df_Y_1$Y_1 - df_Y_0$Y_0)\n      },\n      error = function(e) {\n        df_correct_A1 [i, \"error\"] &lt;&lt;- TRUE\n        df_correct_AvN [i, \"error\"] &lt;&lt;- TRUE\n      }\n    )\n    \n    # Signal progress \n    p()\n  }\n  \n  # Compute performance measures\n  df_performance &lt;- list(\n    IPW_A1 = df_IPW_A1,\n    IPW_AvN = df_IPW_AvN,\n    regression_A1 = df_regression_A1,\n    regression_AvN = df_regression_AvN,\n    path_A1 = df_path_A1,\n    path_AvN = df_path_AvN,\n    ttest_AvN = df_ttest_AvN,\n    correct_A1 = df_correct_A1,\n    correct_AvN = df_correct_AvN\n  ) |&gt;\n    purrr::map_dfr(\n      function(x) {\n        x |&gt; \n          summarise(\n            error = sum(error),\n            inadmissible = sum(inadmissible), \n            not_converged = sum(not_converged),\n            est_bias = mean(est - PV, na.rm = TRUE),\n            est_bias = mean((est - PV)^2, na.rm = TRUE), \n            PV = mean(PV, na.rm = TRUE)\n          )\n      },\n      .id = \"model\"\n    ) |&gt;\n    mutate(\n      id_funcForm = id_funcForm, \n      sample_size = sample_size, \n      prop_exposed = as.numeric(condition[\"prop_exposed\"])\n    ) \n  \n  # Collect point estimates in long-format\n  df_estimates &lt;- bind_rows(\n    list(\n      IPW_A1 = df_IPW_A1,\n      IPW_AvN = df_IPW_AvN,\n      regression_A1 = df_regression_A1,\n      regression_AvN = df_regression_AvN,\n      path_A1 = df_path_A1,\n      path_AvN = df_path_AvN,\n      ttest_AvN = df_ttest_AvN,\n      correct_A1 = df_correct_A1,\n      correct_AvN = df_correct_AvN\n    ),\n    .id = \"model\"\n  ) |&gt; \n    mutate(\n      bias = est - PV,\n      id_funcForm = id_funcForm, \n      sample_size = sample_size, \n      prop_exposed = as.numeric(condition[\"prop_exposed\"])\n    ) |&gt;\n    select(model, bias, id_funcForm, sample_size, prop_exposed)\n  \n  # Collect proportion exposed in sample\n  df_prop_exposed &lt;- df_prop_exposed |&gt;\n    mutate(\n      id_funcForm = id_funcForm, \n      sample_size = sample_size, \n      target_prop_exposed = as.numeric(condition[\"prop_exposed\"]),\n      sample_prop_exposed_A1 = n_exposed_A1 / sample_size,\n      sample_prop_exposed_A2 = n_exposed_A2 / sample_size\n    ) |&gt;\n    select(id_funcForm:sample_prop_exposed_A2)\n  \n  # Create repList\n  repList &lt;- paste0(\"df\", 1:n_reps, \"_condition\", id_condition, \".dat\")\n  utils::write.table(repList,\n      file = file.path(save_path, paste0(\"repList_condition\", id_condition, \".dat\")),\n      sep = \"\\t\", col.names = FALSE, row.names = FALSE, quote = FALSE\n  )\n\n  return(list(\n    df_performance = df_performance, \n    df_estimates = df_estimates,\n    df_prop_exposed = df_prop_exposed\n  ))\n}"
  },
  {
    "objectID": "index.html#running-simulations",
    "href": "index.html#running-simulations",
    "title": "Online supplementary materials",
    "section": "Running simulations",
    "text": "Running simulations\nThe below R code for creates a dataframe with the different simulation scenarios in the rows, and the columns containing the factors that define a simulation scenario. The run_condition() function is then called on each row resulting in the generation of data per scenario, and the analysis of the data by various methods. The generated data was exported such that it can be analysed in Mplus as well.\n\nRMplus\n\n\n\n# Specify population parameter values for different data generating mechanisms \nfuncForms &lt;- c(\n  \"\", \n  \"B2_C0L1 &lt;- B2_C0L2 &lt;- 0.1; B2_L1L2 &lt;- 0.3\",\n  \"B2_L2Y &lt;- 0.3; B2_C0Y &lt;- 0.1; B2_L1Y &lt;- 0.15\",\n  \"B2_L1A1 &lt;- 0.5; B2_L1A2 &lt;- 0.25; B2_L2A2 &lt;- 0.5\",\n  \"B2_L1A1 &lt;- 0.5; B2_L1A2 &lt;- 0.25; B2_L2A2 &lt;- 0.5; B2_L2Y &lt;- 0.3; B2_C0Y &lt;- 0.1; B2_L1Y &lt;- 0.15\"\n)\n\n# Specify correct PS model for \"correct\" modeling approach\nm_A1_correct &lt;- c(\n  \"A1 ~ C0 + L1\",\n  \"A1 ~ C0 + L1\",\n  \"A1 ~ C0 + L1\",\n  \"A1 ~ C0 + L1 + I( (L1 - mean(L1))^2 )\",\n  \"A1 ~ C0 + L1 + I( (L1 - mean(L1))^2 )\"\n)\n\nm_A2_correct &lt;- c(\n  \"A2 ~ C0 + A1 + L1 + L2\",\n  \"A2 ~ C0 + A1 + L1 + L2\",\n  \"A2 ~ C0 + A1 + L1 + L2\",\n  \"A2 ~ C0 + A1 + L1 + L2 + I( (L1 - mean(L1))^2 ) + I( (L2 - mean(L2))^2 )\", \n  \"A2 ~ C0 + A1 + L1 + L2 + I( (L1 - mean(L1))^2 ) + I( (L2 - mean(L2))^2 )\"\n)\n\n# Simulation factor 2 - Sample size\nsample_sizes &lt;- c(300, 1000)\n\n# Simulation factor 3 - Proportion exposed\nprops_exposed &lt;- c(.1, .5, .9)\n\n# Set intercepts of binary expose for controlling proportion exposed\nprop_exposed_funcForm &lt;- c(\n  \"B0_A1 &lt;- -3.4; B0_A2 &lt;- -4.18\", # DGM 1\n  \"B0_A1 &lt;- -1.1; B0_A2 &lt;- -2.16\", \n  \"B0_A1 &lt;- 1.2; B0_A2 &lt;- -0.13\",\n  \n  \"B0_A1 &lt;- -3.44; B0_A2 &lt;- -4.45\", # DGM 2\n  \"B0_A1 &lt;- -1.15; B0_A2 &lt;- -2.39\", \n  \"B0_A1 &lt;- 1.14; B0_A2 &lt;- -0.36\",\n  \n  \"B0_A1 &lt;- -3.4; B0_A2 &lt;- -4.18\", # DGM 3\n  \"B0_A1 &lt;- -1.1; B0_A2 &lt;- -2.15\", \n  \"B0_A1 &lt;- 1.2; B0_A2 &lt;- -0.13\",\n  \n  \"B0_A1 &lt;- -4.1; B0_A2 &lt;- -5.31\", # DGM 4\n  \"B0_A1 &lt;- -1.53; B0_A2 &lt;- -2.87\", \n  \"B0_A1 &lt;- 0.8; B0_A2 &lt;- -0.82\",\n  \n  \"B0_A1 &lt;- -4.1; B0_A2 &lt;- -5.31\", # DGM 5\n  \"B0_A1 &lt;- -1.53; B0_A2 &lt;- -2.87\", \n  \"B0_A1 &lt;- 0.8; B0_A2 &lt;- -0.82\"\n) \n\n# Create simulation conditions\nconditions &lt;- data.frame(\n  funcForm = rep(funcForms, each = 3),\n  id_funcForm = rep(c(1:5), each = 3),\n  m_A1_correct = rep(m_A1_correct, each = 3),\n  m_A2_correct = rep(m_A2_correct, each = 3),\n  PV_A1 = rep(PVs_A1, each = 3),\n  PV_AvN = rep(PVs_AvN, each = 3),\n  prop_exposed = rep(props_exposed, times = 5),\n  prop_exposed_funcForm = prop_exposed_funcForm\n) \n\ndf_conditions &lt;- conditions |&gt;\n  bind_rows(conditions) |&gt;\n  mutate(\n    sample_size = rep(sample_sizes, each = nrow(conditions)),\n    id_condition = row_number()\n  ) \n\nconditions &lt;- asplit(df_conditions, 1) \n\n## Run simulations\nn_reps &lt;- 1000\n\nfuture::plan(multisession, workers = 7)\n\nwith_progress({\n  p &lt;- progressor(nrow(conditions)*n_reps)\n\n  out &lt;- furrr::future_map(\n    .x = conditions,\n    .f = run_condition,\n    n_reps = n_reps, \n    p = p,\n    save_folder = \"simulation\",\n    .options = furrr::furrr_options(\n      seed = 20230429\n    ) \n  )\n})\n\nfuture::plan(sequential)\n\n\n\nPer simulation scenario, two Mplus input files were created: One for the analysis using only a linear path model, and one for the analysis using a path model that also contained quadratic relations (when relevant). The syntax below is the linear path model for simulation scenario 13 (DGM 5, sample size of 300, proportion exposed is 0.10). Mplus outputs a text file containing the parameter estimates for each analyzed dataset.\nTITLE:\n   Traditional path analysis for estimating joint effects \n   and prolongued exposure effect.\n   - K = 2 (waves)\n   - All effects assumed linear\n\nDATA:\n    FILE = repList_condition13.dat;\n    TYPE = MONTECARLO;\n\nVARIABLE: \n    NAMES = C0 L1 A1 L2 A2 Y \n            Pr_A1 Pr_A2 ps1 ps2 W W_correct;  \n    USEVARIABLES = C0-Y;\n    MISSING = .;\n    CATEGORICAL = A1 A2;\n\nANALYSIS:\n   ESTIMATOR = ML;\n   LINK = LOGIT; ! Alternatively, LINK = LOGIT\n   ! When ESTIMATOR = WLSMV, LINK defaults to PROBIT. \n   ! When using LINK = LOGIT, use Bootstrapped CI\n\nMODEL:\n    ! Lagged effects on Y\n    Y ON A1*0.2 A2*0.4 (B_A1Y B_A2Y);\n    Y ON L1*0.15 L2*0.3 (B_L1Y B_L2Y);\n    Y ON C0*0.1 (B_C0Y);\n\n    ! Lagged effects on L\n    L2 ON L1*0.3 A1*0.4 C0*0.1 (B_L1L2 B_A1L2 B_C0L2);\n    L1 ON C0*0.1; \n\n    ! Lagged effects on A\n    A2 ON C0 A1 L1 L2;\n    A1 ON C0 L1;\n    \n    ! Variance\n    C0;\n\n    ! Residual variances\n    L1 L2 Y;\n\n    ! Thresholds\n    [A1$1 A2$1] (tau1 tau2);\n    \nMODEL CONSTRAINT:\n    NEW(JTE_A1*0.32);\n    JTE_A1 = B_A1L2*B_L2Y + B_A1Y;\n    \n    NEW(AvN*0.72); \n    AvN = JTE_A1 + B_A2Y;\n\nSAVEDATA:\n    RESULTS = results_condition13.dat;\nThe syntax below is the quadratic path model (i.e., correctly specified) for simulation scenario 13 (DGM 5, sample size of 300, proportion exposed is 0.10).\nTITLE:\n   Traditional path analysis for estimating joint effects \n   and prolongued exposure effect.\n   - K = 2 (waves)\n   - Model correctly specified\n\nDATA:\n    FILE = repList_condition13.dat;\n    TYPE = MONTECARLO;\n\nVARIABLE: \n    NAMES = C0 L1 A1 L2 A2 Y \n            Pr_A1 Pr_A2 ps1 ps2 W W_correct;  \n    USEVARIABLES = C0-Y C0C0 L1L1 L2L2;\n    MISSING = .;\n    CATEGORICAL = A1 A2;\n\nDEFINE: \n    CENTER C0 L1 L2 (GRANDMEAN);\n    C0C0 = C0**2;\n    L1L1 = L1**2;\n    L2L2 = L2**2;\n\nANALYSIS:\n   ESTIMATOR = ML;\n   LINK = LOGIT; ! Alternatively, LINK = LOGIT\n   ! When ESTIMATOR = WLSMV, LINK defaults to PROBIT. \n   ! When using LINK = LOGIT, use Bootstrapped CI\n\nMODEL:\n    ! Lagged effects on Y\n    Y ON A1*0.2 A2*0.4 (B_A1Y B_A2Y);\n    Y ON L1*0.15 L2*0.3 (B_L1Y B_L2Y);\n    Y ON C0*0.1 (B_C0Y);\n    Y ON C0C0*0.1 L1L1*0.15 L2L2*0.3;\n\n    ! Lagged effects on L\n    L2 ON L1*0.3 A1*0.4 C0*0.1 (B_L1L2 B_A1L2 B_C0L2);\n    L2 ON C0C0*0.1 L1L1*0.15;\n    L1 ON C0*0.1 C0C0*0.1; \n\n    ! Lagged effects on A\n    A2 ON C0 A1 L1 L2 L1L1 L2L2;\n    A1 ON C0 L1 L1L1;\n    \n    ! Variance\n    C0;\n\n    ! Residual variances\n    L1 L2 Y;\n\n    ! Thresholds\n    [A1$1 A2$1] (tau1 tau2);\n    \nMODEL CONSTRAINT:\n    NEW(JTE_A1*0.32);\n    JTE_A1 = B_A1L2*B_L2Y + B_A1Y;\n    \n    NEW(AvN*0.72); \n    AvN = JTE_A1 + B_A2Y;\n\nSAVEDATA:\n    RESULTS = results_correct_condition13.dat;"
  },
  {
    "objectID": "index.html#extracting-simulation-results",
    "href": "index.html#extracting-simulation-results",
    "title": "Online supplementary materials",
    "section": "Extracting simulation results",
    "text": "Extracting simulation results\nOutput from the analyses in R are saved in an object called out, and output from Mplus analyses are saved in .dat files per simulation scenario. The below R code collects alls results, and merges them into a single large dataframe.\n\n# Restructure results\nout_performance &lt;- out |&gt;\n  purrr::map(function(x) {x$df_performance}) |&gt;\n  bind_rows(.id = \"condition\")\n\nout_estimates &lt;- out |&gt;\n  purrr::map(function(x) {x$df_estimates}) |&gt;\n  bind_rows(.id = \"condition\")\n\nout_prop_exposed &lt;- out |&gt;\n  purrr::map(function(x) {x$df_prop_exposed}) |&gt;\n  bind_rows(.id = \"condition\")\n\n# Mplus results (linear)\ndf_Mplus_linear &lt;- map(\n  .x = paste0(\".\\\\simulation\\\\condition\", 1:30, \"\\\\results_condition\", 1:30, \".dat\"),\n  .f = read.delim,\n  header = FALSE\n) |&gt; map(slice, seq(4, (8*n_reps) - 4, 8)) |&gt;\n  map(\n    .f = separate, \n    col = V1, \n    into = c(paste0(\"P\", 21:25), \"Mplus_linear_A1\", \"Mplus_linear_AvN\"),\n    sep = c(15, 31, 47, 63, 79, 95)\n  ) |&gt;\n  map(select, Mplus_linear_A1, Mplus_linear_AvN) |&gt;\n  map(\n    .f = pivot_longer, \n    cols = everything(), \n    names_to = \"model\", \n    values_to = \"estimate\",\n    values_transform = list(estimate = as.numeric)\n  ) |&gt;\n  list_rbind(names_to = \"condition\") \n\n## Check if extraction of point estimates was successful: Compare to Mplus .out file\ncheck_linear_A1 &lt;- df_Mplus_linear |&gt; \n  group_by(condition, model) |&gt;\n  summarise(\n    average = mean(estimate),\n    SD = sd(estimate),\n    MSE = mean((estimate - .32)^2)\n  )\n\n## Extract sample_size, prop_exposed, etc. per condition\ndf_Mplus_add &lt;- out_estimates |&gt;\n  group_by(condition) |&gt;\n  slice_head(n = 2*n_reps) |&gt;\n  mutate(condition = as.numeric(condition)) |&gt;\n  select(-bias, -model) |&gt;\n  arrange(condition) |&gt;\n  ungroup()\n\n## Add Mplus (linear) estimate to other results\nout_estimates &lt;- df_Mplus_linear |&gt;\n  cbind(select(df_Mplus_add, id_funcForm, sample_size, prop_exposed)) |&gt;\n  mutate(PV = if_else(model == \"Mplus_linear_A1\", .32, .72), bias = estimate - PV) |&gt;\n  select(-estimate, - PV) |&gt;\n  relocate(bias, .before = id_funcForm) |&gt;\n  rbind(out_estimates)\n\nrm(df_Mplus_add)\n  \n# Read in Mplus results DGM 1 (correct)\nn_params &lt;- 2\nn_props &lt;- 3\nn_sample_sizes &lt;- 2\n\ndf_Mplus_correct_DGM1 &lt;- map(\n  .x = paste0(\".\\\\simulation\\\\condition\", c(1:3, 16:18), \"\\\\results_correct_condition\", c(1:3, 16:18), \".dat\"),\n  .f = read.delim,\n  header = FALSE\n) |&gt; map(slice, seq(4, (8*n_reps) - 4, 8)) |&gt;\n  map(\n    .f = separate, \n    col = V1, \n    into = c(paste0(\"P\", 21:25), \"Mplus_correct_A1\", \"Mplus_correct_AvN\"),\n    sep = c(15, 31, 47, 63, 79, 95)\n  ) |&gt;\n  map(select, Mplus_correct_A1, Mplus_correct_AvN) |&gt;\n  map(\n    .f = pivot_longer, \n    cols = everything(), \n    names_to = \"model\", \n    values_to = \"estimate\",\n    values_transform = list(estimate = as.numeric)\n  ) |&gt;\n  list_rbind() |&gt; \n  mutate(\n    condition = rep(c(1:3, 16:18), each = n_params*n_reps),\n    id_funcForm = 1, \n    sample_size = rep(c(300, 1000), each = n_params*n_reps*n_props),\n    prop_exposed = rep(rep(c(0.1, 0.5, 0.9), each = n_params*n_reps), times = n_sample_sizes),\n    PV = if_else(model == \"Mplus_correct_A1\", .32, .72), \n    bias = estimate - PV\n  ) |&gt;\n  relocate(bias, .before = id_funcForm) |&gt;\n  relocate(condition, .before = model)\n\n## Check if extraction of point estimates was successful: Compare to Mplus .out file\ncheck_correct_DGM1 &lt;- df_Mplus_correct_DGM1 |&gt; \n  group_by(condition, model) |&gt;\n  summarise(\n    average = mean(estimate),\n    SD = sd(estimate),\n    MSE = mean((estimate - PV)^2)\n  )\n\n# Read in Mplus results DGM 2, 3, and 4 (correct)\ndf_Mplus_correct_DGM234 &lt;- map(\n  .x = paste0(\".\\\\simulation\\\\condition\", c(4:12, 19:27), \"\\\\results_correct_condition\", c(4:12, 19:27), \".dat\"),\n  .f = read.delim,\n  header = FALSE\n) |&gt; map(slice, seq(4, (8*n_reps) - 4, 8)) |&gt;\n  map(\n    .f = separate, \n    col = V1, \n    into = c(paste0(\"P\", 21:28), \"Mplus_correct_A1\", \"Mplus_correct_AvN\"),\n    sep = c(15, 31, 47, 63, 79, 95, 111, 127, 143)\n  ) |&gt;\n  map(select, Mplus_correct_A1, Mplus_correct_AvN) |&gt;\n  map(\n    .f = pivot_longer, \n    cols = everything(), \n    names_to = \"model\", \n    values_to = \"estimate\",\n    values_transform = list(estimate = as.numeric)\n  ) |&gt;\n  list_rbind() |&gt; \n  mutate(\n    condition = rep(c(4:12, 19:27), each = n_params*n_reps),\n    id_funcForm = rep(rep(c(2:4), each = n_params*n_props*n_reps), times = n_sample_sizes),\n    sample_size = rep(c(300, 1000), each = n_params*n_reps*n_props*3),\n    prop_exposed = rep(rep(c(0.1, 0.5, 0.9), each = n_params*n_reps), times = 3*n_sample_sizes),\n    PV = if_else(model == \"Mplus_correct_A1\", .32, .72), \n    bias = estimate - PV\n  ) |&gt;\n  relocate(bias, .before = id_funcForm) |&gt;\n  relocate(condition, .before = model)\n\n## Check if extraction of point estimates was successful: Compare to Mplus .out file\ncheck_correct_DGM234 &lt;- df_Mplus_correct_DGM234 |&gt; \n  group_by(condition, model) |&gt;\n  summarise(\n    average = mean(estimate),\n    SD = sd(estimate),\n    MSE = mean((estimate - PV)^2)\n  )\n  \n# Read in Mplus results DGM 5 (correct)\ndf_Mplus_correct_DGM5 &lt;- map(\n  .x = paste0(\".\\\\simulation\\\\condition\", c(13:15, 28:30), \"\\\\results_correct_condition\", c(13:15, 28:30), \".dat\"),\n  .f = read.delim,\n  header = FALSE\n) |&gt; map(slice, seq(5, (10*n_reps) - 5, 10)) |&gt;\n  map(\n    .f = separate, \n    col = V1, \n    into = c(paste0(\"P\", 31:34), \"Mplus_correct_A1\", \"Mplus_correct_AvN\"),\n    sep = c(15, 31, 47, 63, 79)\n  ) |&gt;\n  map(select, Mplus_correct_A1, Mplus_correct_AvN) |&gt;\n  map(\n    .f = pivot_longer, \n    cols = everything(), \n    names_to = \"model\", \n    values_to = \"estimate\",\n    values_transform = list(estimate = as.numeric)\n  ) |&gt;\n  list_rbind() |&gt; \n  mutate(\n    condition = rep(c(13:15, 28:30), each = n_params*n_reps),\n    id_funcForm = 5, \n    sample_size = rep(c(300, 1000), each = n_params*n_reps*n_props),\n    prop_exposed = rep(rep(c(0.1, 0.5, 0.9), each = n_params*n_reps), times = n_sample_sizes),\n    PV = if_else(model == \"Mplus_correct_A1\", .32, .72), \n    bias = estimate - PV\n  ) |&gt;\n  relocate(bias, .before = id_funcForm) |&gt;\n  relocate(condition, .before = model)\n\n## Check if extraction of point estimates was successful: Compare to Mplus .out file\ncheck_correct_DGM5 &lt;- df_Mplus_correct_DGM5 |&gt; \n  group_by(condition, model) |&gt;\n  summarise(\n    average = mean(estimate),\n    SD = sd(estimate),\n    MSE = mean((estimate - PV)^2)\n  )\n\n# Add estimates of Mplus_correct to other estimates\nout_estimates &lt;- map(\n  .x = list(df_Mplus_correct_DGM1, df_Mplus_correct_DGM234, df_Mplus_correct_DGM5),\n  .f = select,\n  -PV, -estimate\n  ) |&gt;\n  reduce(rbind) |&gt;\n  rbind(out_estimates)"
  },
  {
    "objectID": "index.html#visualizing-simulation-results",
    "href": "index.html#visualizing-simulation-results",
    "title": "Online supplementary materials",
    "section": "Visualizing simulation results",
    "text": "Visualizing simulation results\nThe below R code visualizes the results. It can be used to create the Figures 6 and 7 in the main manuscript.\n\nperformance_AvN &lt;- out_estimates |&gt;\n  #filter(sample_size == 1000) |&gt;\n  filter(model == \"IPW_AvN\" | model == \"regression_AvN\" | \n           model ==  \"Mplus_linear_AvN\" | model == \"Mplus_correct_AvN\" |\n           model == \"correct_AvN\") |&gt;\n  mutate(est_AvN = bias + 0.72) |&gt;\n  group_by(model, prop_exposed, id_funcForm, sample_size) |&gt;\n  summarise(\n    est_bias = mean(bias),\n    SE_bias = sqrt( (1 / (1000 * 999)) * sum((est_AvN - mean(est_AvN))^2) ),\n    est_MSE = mean(bias^2),\n    SE_MSE = sqrt( (sum((bias^2 - est_MSE)^2)) / (1000 * 999))\n  ) |&gt;\n  ungroup()\n\n# Visualize performance statistics\nplot_bias_AvN_complete &lt;- performance_AvN |&gt;\n  #filter(prop_exposed == .1 | prop_exposed == .5) |&gt;\n  filter(model != \"ttest_AvN\") |&gt;\n  mutate(\n    model_mod = recode_factor(model, \n      \"IPW_AvN\" = \"IPW (L)\",\n      \"Mplus_linear_AvN\" = \"Path (L)\",\n      \"correct_AvN\" = \"IPW (L, Q)\", \n      \"Mplus_correct_AvN\" = \"Path (L, Q)\",\n      \"regression_AvN\" = \"Unadjusted\"\n    ), \n    prop_exposed_mod = recode(prop_exposed, \n      \"0.1\" = \"10% exposed\",\n      \"0.5\" = \"50% exposed\",\n      \"0.9\" = \"90% exposed\"\n    ),\n    id_funcForm_mod = recode(id_funcForm,\n      \"1\" = \"DGM 1\\nNo misspecification\",\n      \"2\" = \"DGM 2\\nCovariate\",\n      \"3\" = \"DGM 3\\nOutcome\",\n      \"4\" = \"DGM 4\\nExposure\",\n      \"5\" = \"DGM 5\\nCombined\"\n    )\n  ) |&gt;\n  ggplot(aes(x = est_bias, y = as.factor(model_mod), color = as.factor(sample_size))) +\n  geom_point(size = 3) + \n  #geom_pointrange(aes(xmin = est_bias - 1.96*SE_bias, xmax = est_bias + 1.96*SE_bias)) + \n  scale_y_discrete(limits = c(\"Unadjusted\", \"Path (L, Q)\", \"IPW (L, Q)\", \"Path (L)\", \"IPW (L)\")) + \n  scale_x_continuous(n.breaks = 3, limits = c(-.5, .5)) +\n  geom_vline(xintercept = 0, linetype = 2) + \n  facet_grid(prop_exposed_mod ~ as.factor(id_funcForm_mod)) + \n  xlab(\"Bias\") +\n  labs(color = \"Sample size\") +\n  theme(\n    legend.position = \"bottom\", \n    axis.title.y = element_blank(), \n    text = element_text(size = 20)\n  )\n\nggsave(\n  filename = \"./figures/plot_bias_AvN_complete.png\", \n  plot = plot_bias_AvN_complete,\n  width = 14,\n  height = 7\n)\n\nplot_MSE_AvN &lt;- performance_AvN |&gt;\n  #filter(prop_exposed == .1 | prop_exposed == .5) |&gt;\n  filter(model != \"ttest_AvN\") |&gt;\n  mutate(\n    model_mod = recode_factor(model, \n      \"IPW_AvN\" = \"IPW (L)\",\n      \"Mplus_linear_AvN\" = \"Path (L)\",\n      \"correct_AvN\" = \"IPW (L, Q)\", \n      \"Mplus_correct_AvN\" = \"Path (L, Q)\",\n      \"regression_AvN\" = \"Unadjusted\"\n    ), \n    prop_exposed_mod = recode(prop_exposed, \n      \"0.1\" = \"10% exposed\",\n      \"0.5\" = \"50% exposed\",\n      \"0.9\" = \"90% exposed\"\n    ),\n    id_funcForm_mod = recode(id_funcForm,\n      \"1\" = \"DGM 1\\nNo misspecification\",\n      \"2\" = \"DGM 2\\nCovariate\",\n      \"3\" = \"DGM 3\\nOutcome\",\n      \"4\" = \"DGM 4\\nExposure\",\n      \"5\" = \"DGM 5\\nCombined\"\n    )\n  ) |&gt;\n  ggplot(aes(x = est_MSE, y = as.factor(model_mod), color = as.factor(sample_size))) +\n  geom_point(size = 3) + \n  #geom_pointrange(aes(xmin = est_MSE - 1.96*SE_MSE, xmax = est_MSE + 1.96*SE_MSE)) + \n  scale_y_discrete(limits = c(\"Unadjusted\", \"Path (L, Q)\", \"IPW (L, Q)\", \"Path (L)\", \"IPW (L)\")) + \n  scale_x_continuous(n.breaks = 3, limits = c(0, 1)) +\n  geom_vline(xintercept = 0, linetype = 2) + \n  facet_grid(prop_exposed_mod ~ as.factor(id_funcForm_mod)) + \n  xlab(\"MSE\") +\n  labs(color = \"Sample size\") +\n  theme(\n    legend.position = \"bottom\", \n    axis.title.y = element_blank(), \n    text = element_text(size = 20)\n  )\n\nggsave(\n  filename = \"./figures/plot_MSE_AvN_complete.png\", \n  plot = plot_MSE_AvN,\n  width = 14,\n  height = 7\n)\n\n# Visualize raw data\nplot_estimates_AvN &lt;- out_estimates |&gt;\n  filter(sample_size == 1000 & (prop_exposed == .1 | prop_exposed == .5)) |&gt;\n  filter(model == \"IPW_AvN\" | model == \"regression_AvN\" | \n           model ==  \"Mplus_linear_AvN\" | model == \"Mplus_correct_AvN\" |\n           model == \"correct_AvN\") |&gt;\n  mutate(\n    est_AvN = bias + 0.72,\n    model_mod = recode_factor(model, \n      \"IPW_AvN\" = \"MSM (L)\",\n      \"Mplus_linear_AvN\" = \"SEM (L)\",\n      \"correct_AvN\" = \"MSM (C)\", \n      \"Mplus_correct_AvN\" = \"SEM (C)\",\n      \"regression_AvN\" = \"Unadjusted\"\n    ), \n    prop_exposed_mod = recode(prop_exposed, \n      \"0.1\" = \"10% exposed\",\n      \"0.5\" = \"50% exposed\"\n    ),\n    id_funcForm_mod = recode(id_funcForm,\n      \"1\" = \"DGM 1\\nNo misspecification\",\n      \"2\" = \"DGM 2\\nCovariate\",\n      \"3\" = \"DGM 3\\nOutcome\",\n      \"4\" = \"DGM 4\\nExposure\",\n      \"5\" = \"DGM 5\\nCombined\"\n    )\n  ) |&gt;\n  ggplot(aes(x = est_AvN, y = as.factor(model_mod), fill = as.factor(model_mod))) + \n  ggridges::geom_density_ridges(\n    scale = .9, \n    quantile_lines = TRUE,\n    quantiles = c(.025, .5, .975),\n    alpha = .7\n  ) + \n  scale_y_discrete(limits = rev) + \n  geom_vline(xintercept = 0.72, linetype = 2) + \n  facet_grid(prop_exposed_mod ~ as.factor(id_funcForm_mod)) + \n  scale_x_continuous(n.breaks = 5, limits = c(-1, 3)) +\n  xlab(expression(hat(theta))) + \n  theme(\n    legend.position = \"none\", \n    axis.title.y = element_blank(), \n    text = element_text(size = 10)\n  ) + \n  scale_fill_viridis_d(option = \"D\") # Colorblind-safe colours\n\nggsave(\n  filename = \"./figures/plot_estimates_AvN.png\", \n  plot = plot_estimates_AvN,\n  width = 7,\n  height = 7\n)"
  }
]